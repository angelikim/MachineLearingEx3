{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning \n",
    "<font color=\"PURPLE\" size=4>Assignment : </font> 3\n",
    "<br>\n",
    "<font color=\"PURPLE\" size=4>Author: </font> Mylonaki Angeliki\n",
    "<br>\n",
    "<font color=\"PURPLE\" size=4>Applying Classification Project Template in MNIST Dataset<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Project\n",
    "\n",
    "1. Load libraries\n",
    "2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from numpy import set_printoptions\n",
    "\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0       1       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       1       0       0       0       0       0       0       0       0   \n",
      "3       4       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "5       0       0       0       0       0       0       0       0       0   \n",
      "6       7       0       0       0       0       0       0       0       0   \n",
      "7       3       0       0       0       0       0       0       0       0   \n",
      "8       5       0       0       0       0       0       0       0       0   \n",
      "9       3       0       0       0       0       0       0       0       0   \n",
      "10      8       0       0       0       0       0       0       0       0   \n",
      "11      9       0       0       0       0       0       0       0       0   \n",
      "12      1       0       0       0       0       0       0       0       0   \n",
      "13      3       0       0       0       0       0       0       0       0   \n",
      "14      3       0       0       0       0       0       0       0       0   \n",
      "15      1       0       0       0       0       0       0       0       0   \n",
      "16      2       0       0       0       0       0       0       0       0   \n",
      "17      0       0       0       0       0       0       0       0       0   \n",
      "18      7       0       0       0       0       0       0       0       0   \n",
      "19      5       0       0       0       0       0       0       0       0   \n",
      "\n",
      "    pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0        0    ...            0         0         0         0         0   \n",
      "1        0    ...            0         0         0         0         0   \n",
      "2        0    ...            0         0         0         0         0   \n",
      "3        0    ...            0         0         0         0         0   \n",
      "4        0    ...            0         0         0         0         0   \n",
      "5        0    ...            0         0         0         0         0   \n",
      "6        0    ...            0         0         0         0         0   \n",
      "7        0    ...            0         0         0         0         0   \n",
      "8        0    ...            0         0         0         0         0   \n",
      "9        0    ...            0         0         0         0         0   \n",
      "10       0    ...            0         0         0         0         0   \n",
      "11       0    ...            0         0         0         0         0   \n",
      "12       0    ...            0         0         0         0         0   \n",
      "13       0    ...            0         0         0         0         0   \n",
      "14       0    ...            0         0         0         0         0   \n",
      "15       0    ...            0         0         0         0         0   \n",
      "16       0    ...            0         0         0         0         0   \n",
      "17       0    ...            0         0         0         0         0   \n",
      "18       0    ...            0         0         0         0         0   \n",
      "19       0    ...            0         0         0         0         0   \n",
      "\n",
      "    pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0          0         0         0         0         0  \n",
      "1          0         0         0         0         0  \n",
      "2          0         0         0         0         0  \n",
      "3          0         0         0         0         0  \n",
      "4          0         0         0         0         0  \n",
      "5          0         0         0         0         0  \n",
      "6          0         0         0         0         0  \n",
      "7          0         0         0         0         0  \n",
      "8          0         0         0         0         0  \n",
      "9          0         0         0         0         0  \n",
      "10         0         0         0         0         0  \n",
      "11         0         0         0         0         0  \n",
      "12         0         0         0         0         0  \n",
      "13         0         0         0         0         0  \n",
      "14         0         0         0         0         0  \n",
      "15         0         0         0         0         0  \n",
      "16         0         0         0         0         0  \n",
      "17         0         0         0         0         0  \n",
      "18         0         0         0         0         0  \n",
      "19         0         0         0         0         0  \n",
      "\n",
      "[20 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./digit_recognizer_dataset.csv\")\n",
    "df_subset=df[:500]\n",
    "print(df_subset.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Problem\n",
    "What is your task? What are your goals? What do you want to achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the combination of the pixels (columns) present in the dataset, we want to find the best model and develop it in odrer to predict digits given data in the same format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Analysis\n",
    "Understand your data: Take a “peek” of your data, answer basic questions about the dataset.\n",
    "Summarise your data. Explore descriptive statistics and visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0       1       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       1       0       0       0       0       0       0       0       0   \n",
      "3       4       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "5       0       0       0       0       0       0       0       0       0   \n",
      "6       7       0       0       0       0       0       0       0       0   \n",
      "7       3       0       0       0       0       0       0       0       0   \n",
      "8       5       0       0       0       0       0       0       0       0   \n",
      "9       3       0       0       0       0       0       0       0       0   \n",
      "10      8       0       0       0       0       0       0       0       0   \n",
      "11      9       0       0       0       0       0       0       0       0   \n",
      "12      1       0       0       0       0       0       0       0       0   \n",
      "13      3       0       0       0       0       0       0       0       0   \n",
      "14      3       0       0       0       0       0       0       0       0   \n",
      "15      1       0       0       0       0       0       0       0       0   \n",
      "16      2       0       0       0       0       0       0       0       0   \n",
      "17      0       0       0       0       0       0       0       0       0   \n",
      "18      7       0       0       0       0       0       0       0       0   \n",
      "19      5       0       0       0       0       0       0       0       0   \n",
      "\n",
      "    pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0        0    ...            0         0         0         0         0   \n",
      "1        0    ...            0         0         0         0         0   \n",
      "2        0    ...            0         0         0         0         0   \n",
      "3        0    ...            0         0         0         0         0   \n",
      "4        0    ...            0         0         0         0         0   \n",
      "5        0    ...            0         0         0         0         0   \n",
      "6        0    ...            0         0         0         0         0   \n",
      "7        0    ...            0         0         0         0         0   \n",
      "8        0    ...            0         0         0         0         0   \n",
      "9        0    ...            0         0         0         0         0   \n",
      "10       0    ...            0         0         0         0         0   \n",
      "11       0    ...            0         0         0         0         0   \n",
      "12       0    ...            0         0         0         0         0   \n",
      "13       0    ...            0         0         0         0         0   \n",
      "14       0    ...            0         0         0         0         0   \n",
      "15       0    ...            0         0         0         0         0   \n",
      "16       0    ...            0         0         0         0         0   \n",
      "17       0    ...            0         0         0         0         0   \n",
      "18       0    ...            0         0         0         0         0   \n",
      "19       0    ...            0         0         0         0         0   \n",
      "\n",
      "    pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0          0         0         0         0         0  \n",
      "1          0         0         0         0         0  \n",
      "2          0         0         0         0         0  \n",
      "3          0         0         0         0         0  \n",
      "4          0         0         0         0         0  \n",
      "5          0         0         0         0         0  \n",
      "6          0         0         0         0         0  \n",
      "7          0         0         0         0         0  \n",
      "8          0         0         0         0         0  \n",
      "9          0         0         0         0         0  \n",
      "10         0         0         0         0         0  \n",
      "11         0         0         0         0         0  \n",
      "12         0         0         0         0         0  \n",
      "13         0         0         0         0         0  \n",
      "14         0         0         0         0         0  \n",
      "15         0         0         0         0         0  \n",
      "16         0         0         0         0         0  \n",
      "17         0         0         0         0         0  \n",
      "18         0         0         0         0         0  \n",
      "19         0         0         0         0         0  \n",
      "\n",
      "[20 rows x 785 columns]\n",
      "            label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  \\\n",
      "count  500.000000   500.0   500.0   500.0   500.0   500.0   500.0   500.0   \n",
      "mean     4.312000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "std      2.910601     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "min      0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "25%      2.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "50%      4.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "75%      7.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "max      9.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "       pixel7  pixel8    ...     pixel774  pixel775  pixel776  pixel777  \\\n",
      "count   500.0   500.0    ...        500.0     500.0     500.0     500.0   \n",
      "mean      0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "std       0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "min       0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "25%       0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "50%       0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "75%       0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "max       0.0     0.0    ...          0.0       0.0       0.0       0.0   \n",
      "\n",
      "       pixel778  pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "count     500.0     500.0     500.0     500.0     500.0     500.0  \n",
      "mean        0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "std         0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "min         0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "25%         0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "50%         0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "75%         0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "max         0.0       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[8 rows x 785 columns]\n",
      "(500, 785)\n",
      "label       int64\n",
      "pixel0      int64\n",
      "pixel1      int64\n",
      "pixel2      int64\n",
      "pixel3      int64\n",
      "pixel4      int64\n",
      "pixel5      int64\n",
      "pixel6      int64\n",
      "pixel7      int64\n",
      "pixel8      int64\n",
      "pixel9      int64\n",
      "pixel10     int64\n",
      "pixel11     int64\n",
      "pixel12     int64\n",
      "pixel13     int64\n",
      "pixel14     int64\n",
      "pixel15     int64\n",
      "pixel16     int64\n",
      "pixel17     int64\n",
      "pixel18     int64\n",
      "pixel19     int64\n",
      "pixel20     int64\n",
      "pixel21     int64\n",
      "pixel22     int64\n",
      "pixel23     int64\n",
      "pixel24     int64\n",
      "pixel25     int64\n",
      "pixel26     int64\n",
      "pixel27     int64\n",
      "pixel28     int64\n",
      "            ...  \n",
      "pixel754    int64\n",
      "pixel755    int64\n",
      "pixel756    int64\n",
      "pixel757    int64\n",
      "pixel758    int64\n",
      "pixel759    int64\n",
      "pixel760    int64\n",
      "pixel761    int64\n",
      "pixel762    int64\n",
      "pixel763    int64\n",
      "pixel764    int64\n",
      "pixel765    int64\n",
      "pixel766    int64\n",
      "pixel767    int64\n",
      "pixel768    int64\n",
      "pixel769    int64\n",
      "pixel770    int64\n",
      "pixel771    int64\n",
      "pixel772    int64\n",
      "pixel773    int64\n",
      "pixel774    int64\n",
      "pixel775    int64\n",
      "pixel776    int64\n",
      "pixel777    int64\n",
      "pixel778    int64\n",
      "pixel779    int64\n",
      "pixel780    int64\n",
      "pixel781    int64\n",
      "pixel782    int64\n",
      "pixel783    int64\n",
      "Length: 785, dtype: object\n",
      "\u001b[95m\n",
      "There are no missing values in given dataset\n",
      "\u001b[0m\n",
      "\u001b[1mClass distribution: \u001b[0mlabel\n",
      "0    56\n",
      "1    50\n",
      "2    63\n",
      "3    48\n",
      "4    54\n",
      "5    42\n",
      "6    46\n",
      "7    47\n",
      "8    41\n",
      "9    53\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Peek of our data\n",
    "print(df_subset.head(20))\n",
    "\n",
    "#Descriptive Statistics\n",
    "print(df_subset.describe())\n",
    "\n",
    "#Data dimentions\n",
    "print df_subset.shape\n",
    "\n",
    "#Data types\n",
    "print df_subset.dtypes\n",
    "\n",
    "#Checking for missing values\n",
    "if not df_subset.isnull().any().any():\n",
    "    print color.PURPLE + \"\\nThere are no missing values in given dataset\\n\" + color.END\n",
    "else:\n",
    "    print \"\\nThere are missing values in the dataset...\\nExiting...\"\n",
    "    exit\n",
    "    \n",
    "#class distribution\n",
    "print color.BOLD + \"Class distribution: \"+ color.END + str(df_subset.groupby('label').size())\n",
    "\n",
    "def plot_correlations(NoElements, labels):\n",
    "    correlations = df.corr()\n",
    "    # plot correlation matrix\n",
    "    fig = plt.figure(figsize=(15, 14))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "    fig.colorbar(cax)\n",
    "    ticks = np.arange(0,NoElements,1)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_histogram(dataset):\n",
    "    dataset.hist()\n",
    "    plt.show()\n",
    "\n",
    "def plot_scatter_matrix(dataset):\n",
    "    scatter_matrix(dataset,figsize=(8,8))\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_data(dataset,NoElements,labels):    \n",
    "    plot_correlations(NoElements,labels)\n",
    "    plot_histogram(dataset)\n",
    "    plot_scatter_matrix(dataset)\n",
    "\n",
    "features=[\"pixel\" + str(i) for i in range(1,784)]\n",
    "#visualize_data(df_subset,784,features) #Cannot really calculate correlations in my PC :( \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data\n",
    "Data Cleaning/Data Wrangling/Collect more data (if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNormalizing data.....\u001b[0m\n",
      "\u001b[1mPrinting example.....\u001b[0m\n",
      "[ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.006  0.009  0.043  0.043  0.06   0.027  0.022  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.004  0.027  0.078  0.079  0.079\n",
      "  0.079  0.079  0.068  0.077  0.047  0.01   0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.005  0.056  0.079  0.079  0.079  0.079  0.079  0.079  0.079  0.079\n",
      "  0.079  0.072  0.017  0.005  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.022  0.079  0.079\n",
      "  0.079  0.079  0.079  0.079  0.079  0.079  0.079  0.079  0.079  0.079\n",
      "  0.032  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.019  0.06   0.079  0.079  0.079  0.079  0.079\n",
      "  0.034  0.026  0.062  0.079  0.079  0.079  0.079  0.076  0.027  0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.054\n",
      "  0.079  0.079  0.079  0.063  0.046  0.046  0.014  0.     0.003  0.009\n",
      "  0.062  0.079  0.079  0.079  0.053  0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.054  0.079  0.079  0.028\n",
      "  0.021  0.     0.     0.     0.     0.     0.     0.04   0.079  0.079\n",
      "  0.079  0.066  0.024  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.015  0.079  0.079  0.079  0.009  0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.026  0.079  0.079  0.079  0.048  0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.025  0.079\n",
      "  0.079  0.075  0.007  0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.008  0.075  0.079  0.079  0.048  0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.02   0.079  0.079  0.058  0.002  0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.052  0.079  0.079\n",
      "  0.07   0.004  0.     0.     0.     0.     0.     0.     0.     0.     0.004\n",
      "  0.072  0.079  0.079  0.079  0.009  0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.023  0.079  0.079  0.079  0.005  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.006  0.079  0.079  0.079  0.079\n",
      "  0.009  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.015\n",
      "  0.079  0.079  0.079  0.005  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.001  0.051  0.079  0.079  0.079  0.009  0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.015  0.079  0.079  0.079  0.005  0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.029  0.079\n",
      "  0.079  0.079  0.062  0.004  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.005  0.065  0.079  0.079  0.047  0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.005  0.064  0.079  0.079  0.079  0.063\n",
      "  0.021  0.     0.     0.     0.     0.     0.007  0.05   0.079  0.079\n",
      "  0.077  0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.019  0.066  0.079  0.079  0.079  0.061  0.015  0.015\n",
      "  0.011  0.013  0.015  0.065  0.079  0.079  0.079  0.053  0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.027\n",
      "  0.076  0.079  0.079  0.079  0.079  0.079  0.073  0.076  0.079  0.079\n",
      "  0.079  0.079  0.079  0.027  0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.036  0.079  0.079\n",
      "  0.079  0.079  0.079  0.079  0.079  0.079  0.079  0.079  0.075  0.027\n",
      "  0.003  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.004  0.057  0.079  0.079  0.079  0.079\n",
      "  0.079  0.079  0.079  0.079  0.076  0.022  0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.002  0.024  0.046  0.079  0.08   0.079  0.08   0.046  0.006\n",
      "  0.005  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      "\u001b[1m\n",
      "Standardizing data.....\u001b[0m\n",
      "\u001b[1mPrinting example.....\u001b[0m\n",
      "[  0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00  -4.477e-02\n",
      "  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00  -4.518e-02\n",
      "  -7.528e-02  -1.041e-01  -1.111e-01  -1.116e-01  -1.059e-01  -1.353e-01\n",
      "  -1.188e-01  -1.111e-01  -1.152e-01  -1.135e-01  -1.028e-01  -7.929e-02\n",
      "  -5.344e-02  -4.477e-02   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "  -4.477e-02  -4.477e-02  -7.108e-02  -1.163e-01  -1.531e-01  -1.691e-01\n",
      "  -2.039e-01  -2.303e-01  -2.564e-01  -2.616e-01  -2.741e-01  -2.717e-01\n",
      "  -2.235e-01  -2.104e-01  -1.914e-01  -1.383e-01  -9.669e-02  -7.997e-02\n",
      "  -5.009e-02  -4.477e-02   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00  -4.793e-02  -8.663e-02\n",
      "  -1.549e-01  -2.161e-01  -1.843e-02   3.839e-02   1.052e+00   7.588e-01\n",
      "   1.077e+00   1.576e-01   5.702e-02  -4.986e-01  -4.457e-01  -3.717e-01\n",
      "  -3.270e-01  -2.428e-01  -1.663e-01  -1.267e-01  -9.049e-02  -5.339e-02\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "  -4.477e-02  -6.296e-02  -1.430e-01  -2.149e-01  -9.192e-02   5.800e-01\n",
      "   1.980e+00   1.649e+00   1.325e+00   1.060e+00   9.379e-01   6.287e-01\n",
      "   8.206e-01   3.055e-01  -3.986e-01  -5.456e-01  -4.803e-01  -3.710e-01\n",
      "  -2.634e-01  -1.811e-01  -1.328e-01  -9.399e-02   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00  -5.533e-02  -9.545e-02  -1.038e-01\n",
      "  -2.060e-01  -7.666e-02   1.555e+00   1.839e+00   1.484e+00   1.146e+00\n",
      "   8.724e-01   7.380e-01   6.887e-01   6.243e-01   6.042e-01   7.051e-01\n",
      "   7.734e-01  -3.261e-01  -4.945e-01  -5.038e-01  -3.788e-01  -2.490e-01\n",
      "  -1.549e-01  -1.008e-01   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00  -6.191e-02  -1.183e-01  -1.652e-01  -2.717e-01   4.649e-01\n",
      "   1.901e+00   1.425e+00   1.174e+00   8.674e-01   6.783e-01   5.989e-01\n",
      "   5.324e-01   4.703e-01   4.756e-01   5.972e-01   7.548e-01   9.493e-01\n",
      "   6.694e-02  -5.582e-01  -4.099e-01  -2.831e-01  -1.811e-01  -1.084e-01\n",
      "  -4.477e-02   0.000e+00   0.000e+00   0.000e+00   0.000e+00  -6.680e-02\n",
      "  -1.368e-01  -2.115e-01   5.344e-01   1.439e+00   1.521e+00   1.214e+00\n",
      "   9.670e-01   7.650e-01   6.468e-01  -3.542e-01  -5.108e-01   1.546e-01\n",
      "   5.165e-01   6.025e-01   6.970e-01   8.472e-01   1.009e+00   8.252e-02\n",
      "  -4.391e-01  -3.075e-01  -2.059e-01  -1.268e-01  -4.477e-02   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00  -5.500e-02  -1.507e-01  -2.425e-01\n",
      "   1.812e+00   1.955e+00   1.474e+00   1.240e+00   5.661e-01   4.826e-02\n",
      "   3.918e-02  -6.026e-01  -8.433e-01  -7.984e-01  -6.821e-01   3.785e-01\n",
      "   7.328e-01   8.616e-01   1.114e+00   8.209e-01  -4.403e-01  -2.993e-01\n",
      "  -1.848e-01  -1.215e-01  -4.975e-02  -4.477e-02   0.000e+00  -4.477e-02\n",
      "  -4.477e-02  -6.288e-02  -1.438e-01  -2.159e-01   1.804e+00   1.951e+00\n",
      "   1.472e+00  -8.136e-02  -3.991e-01  -8.755e-01  -8.283e-01  -7.234e-01\n",
      "  -6.960e-01  -7.170e-01  -7.710e-01  -6.482e-02   7.673e-01   8.986e-01\n",
      "   1.145e+00   1.328e+00   4.727e-01  -2.824e-01  -1.618e-01  -5.967e-02\n",
      "  -4.477e-02  -4.477e-02   0.000e+00  -4.477e-02  -4.477e-02  -7.626e-02\n",
      "  -1.374e-01   5.696e-01   2.839e+00   1.931e+00   1.310e+00  -6.132e-01\n",
      "  -8.521e-01  -8.080e-01  -7.609e-01  -6.847e-01  -6.612e-01  -7.159e-01\n",
      "  -8.260e-01  -9.207e-01  -3.564e-01   9.036e-01   1.265e+00   1.945e+00\n",
      "   1.514e+00  -2.739e-01  -1.646e-01  -6.215e-02   0.000e+00   0.000e+00\n",
      "   0.000e+00  -4.477e-02  -4.477e-02  -7.159e-02  -1.314e-01   1.127e+00\n",
      "   2.740e+00   1.796e+00   1.111e+00  -6.607e-01  -8.562e-01  -7.788e-01\n",
      "  -7.133e-01  -7.023e-01  -7.307e-01  -8.276e-01  -9.370e-01  -1.017e+00\n",
      "  -7.620e-01   8.792e-01   1.445e+00   2.029e+00   1.496e+00  -2.700e-01\n",
      "  -1.687e-01  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00  -7.462e-02  -1.314e-01   8.941e-01   2.518e+00   1.643e+00\n",
      "   6.497e-01  -7.703e-01  -8.020e-01  -7.613e-01  -7.761e-01  -8.138e-01\n",
      "  -8.712e-01  -9.816e-01  -1.087e+00  -1.073e+00  -9.562e-01   4.092e-01\n",
      "   1.586e+00   2.100e+00   2.456e+00  -8.298e-02  -1.755e-01  -5.474e-02\n",
      "  -4.477e-02   0.000e+00   0.000e+00   0.000e+00   0.000e+00  -5.821e-02\n",
      "   2.175e-01   3.687e+00   2.296e+00   1.523e+00   1.206e+00  -5.791e-01\n",
      "  -7.938e-01  -7.916e-01  -8.959e-01  -9.912e-01  -1.059e+00  -1.150e+00\n",
      "  -1.153e+00  -1.085e+00  -9.568e-01  -2.175e-01   1.555e+00   2.126e+00\n",
      "   2.762e+00  -1.116e-02  -1.824e-01  -6.285e-02  -4.477e-02   0.000e+00\n",
      "   0.000e+00   0.000e+00  -4.477e-02  -8.771e-02   3.050e-01   3.503e+00\n",
      "   2.108e+00   1.522e+00   1.272e+00  -5.570e-01  -8.037e-01  -8.802e-01\n",
      "  -9.922e-01  -1.096e+00  -1.174e+00  -1.199e+00  -1.111e+00  -1.017e+00\n",
      "  -8.895e-01  -4.072e-01   1.488e+00   1.953e+00   2.711e+00  -1.206e-02\n",
      "  -1.808e-01  -4.477e-02  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00\n",
      "  -4.477e-02  -8.380e-02  -1.272e-01   1.880e+00   1.998e+00   1.540e+00\n",
      "   1.300e+00  -4.985e-01  -7.879e-01  -8.569e-01  -9.309e-01  -9.969e-01\n",
      "  -1.067e+00  -1.093e+00  -1.017e+00  -9.684e-01  -8.601e-01  -4.073e-01\n",
      "   1.381e+00   1.890e+00   2.713e+00  -3.505e-04  -1.762e-01  -5.035e-02\n",
      "  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00  -4.477e-02  -7.388e-02\n",
      "  -2.024e-01   8.032e-01   2.015e+00   1.647e+00   1.438e+00   8.597e-01\n",
      "  -6.152e-01  -7.762e-01  -8.109e-01  -8.435e-01  -9.280e-01  -9.743e-01\n",
      "  -1.002e+00  -9.431e-01  -7.233e-01   7.885e-01   1.355e+00   1.819e+00\n",
      "   1.410e+00  -2.601e-01  -1.768e-01  -9.870e-02  -6.275e-02  -4.477e-02\n",
      "   0.000e+00   0.000e+00  -4.477e-02  -8.317e-02  -2.177e-01  -1.834e-01\n",
      "   1.595e+00   1.790e+00   1.514e+00   1.432e+00   7.644e-01  -3.039e-01\n",
      "  -7.623e-01  -7.807e-01  -8.874e-01  -1.003e+00  -1.021e+00  -7.974e-01\n",
      "   2.912e-01   1.227e+00   1.494e+00   1.993e+00   4.649e-02  -2.680e-01\n",
      "  -1.710e-01  -8.960e-02  -5.424e-02  -4.477e-02   0.000e+00   0.000e+00\n",
      "  -6.119e-02  -9.985e-02  -2.227e-01  -3.778e-01   1.152e-01   1.307e+00\n",
      "   1.462e+00   1.221e+00   1.030e+00   5.474e-01  -4.724e-01  -5.421e-01\n",
      "  -7.691e-01  -8.214e-01  -7.383e-01   4.961e-01   9.884e-01   1.288e+00\n",
      "   1.624e+00   1.377e+00  -3.238e-01  -2.323e-01  -1.422e-01  -6.521e-02\n",
      "  -4.477e-02   0.000e+00   0.000e+00   0.000e+00  -4.477e-02  -1.194e-01\n",
      "  -2.297e-01  -3.728e-01  -4.781e-01   1.440e-01   1.198e+00   1.031e+00\n",
      "   8.801e-01   8.145e-01   7.793e-01   6.196e-01   3.327e-01   3.717e-01\n",
      "   6.212e-01   7.951e-01   1.028e+00   1.446e+00   1.822e+00   6.009e-01\n",
      "  -2.697e-01  -1.797e-01  -1.302e-01  -7.297e-02   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00  -4.477e-02  -9.087e-02  -1.947e-01  -3.462e-01\n",
      "  -4.450e-01  -5.693e-01   1.809e-01   9.652e-01   7.611e-01   6.191e-01\n",
      "   5.835e-01   4.715e-01   3.810e-01   5.131e-01   7.742e-01   9.755e-01\n",
      "   1.273e+00   1.699e+00   5.272e-01  -1.511e-01  -2.060e-01  -1.586e-01\n",
      "  -1.116e-01  -7.506e-02   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "  -4.477e-02  -7.554e-02  -1.615e-01  -2.723e-01  -3.841e-01  -4.991e-01\n",
      "  -5.251e-01   5.280e-01   7.953e-01   6.312e-01   5.454e-01   5.239e-01\n",
      "   5.547e-01   7.447e-01   1.058e+00   1.396e+00   1.735e+00   4.087e-01\n",
      "  -3.103e-01  -2.173e-01  -1.445e-01  -1.085e-01  -9.145e-02  -6.834e-02\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00  -6.121e-02\n",
      "  -9.114e-02  -1.741e-01  -2.853e-01  -3.777e-01  -4.980e-01  -5.331e-01\n",
      "  -1.651e-01   1.826e-01   8.356e-01   8.286e-01   9.494e-01   1.221e+00\n",
      "   6.823e-01  -2.311e-01  -1.504e-01  -2.762e-01  -2.099e-01  -1.507e-01\n",
      "  -8.466e-02  -6.198e-02  -4.773e-02  -4.477e-02   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00  -4.477e-02  -4.477e-02  -1.026e-01\n",
      "  -1.396e-01  -2.089e-01  -3.038e-01  -3.625e-01  -4.201e-01  -4.741e-01\n",
      "  -5.036e-01  -5.242e-01  -4.947e-01  -4.190e-01  -3.562e-01  -2.935e-01\n",
      "  -2.346e-01  -1.875e-01  -1.345e-01  -6.602e-02  -4.477e-02  -4.477e-02\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00  -6.759e-02  -7.756e-02  -1.220e-01\n",
      "  -1.901e-01  -2.253e-01  -2.504e-01  -2.678e-01  -3.056e-01  -3.291e-01\n",
      "  -3.049e-01  -2.669e-01  -2.083e-01  -1.800e-01  -1.496e-01  -1.182e-01\n",
      "  -7.479e-02  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00  -7.039e-02  -1.004e-01  -1.292e-01\n",
      "  -1.458e-01  -1.558e-01  -1.643e-01  -2.082e-01  -1.926e-01  -1.824e-01\n",
      "  -1.475e-01  -1.188e-01  -7.713e-02  -5.158e-02  -4.477e-02   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00  -4.477e-02  -4.477e-02   0.000e+00   0.000e+00  -4.477e-02\n",
      "  -4.477e-02  -6.692e-02  -6.334e-02  -6.564e-02  -5.022e-02  -4.477e-02\n",
      "   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00\n",
      "   0.000e+00   0.000e+00   0.000e+00]\n"
     ]
    }
   ],
   "source": [
    "array = df_subset.values\n",
    "# separate array into input and output components\n",
    "X = array[:,1:784]\n",
    "Y = array[:,0]\n",
    "#Getting all possible label values\n",
    "class_names=np.unique(Y).tolist()\n",
    "\n",
    "#Normalization\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "# summarise transformed data\n",
    "set_printoptions(precision=3)\n",
    "print color.BOLD + \"Normalizing data.....\" + color.END\n",
    "print color.BOLD + \"Printing example.....\" +color.END\n",
    "print(normalizedX[1])\n",
    "\n",
    "\n",
    "print color.BOLD + \"\\nStandardizing data.....\" + color.END\n",
    "print color.BOLD + \"Printing example.....\" + color.END\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(normalizedX)\n",
    "rescaledX = scaler.transform(normalizedX)\n",
    "# summarise transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature Engineering\n",
    "Feature selection/feture engineering (as in new features)/data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.538e+00  -7.226e+00  -8.239e-01 ...,   8.266e-03   1.971e-02\n",
      "    3.457e-15]\n",
      " [  1.402e+01  -7.591e-03   3.685e+00 ...,  -4.154e-03   7.292e-03\n",
      "    3.457e-15]\n",
      " [ -8.435e+00  -2.735e+00   7.181e-01 ...,  -2.113e-02  -3.736e-03\n",
      "    3.457e-15]\n",
      " ..., \n",
      " [ -9.051e+00  -2.774e+00   1.347e+00 ...,  -6.843e-03   4.984e-02\n",
      "    3.457e-15]\n",
      " [  2.336e+00  -8.318e-01  -3.957e+00 ...,  -3.664e-03   1.926e-03\n",
      "    3.457e-15]\n",
      " [  1.258e+01   4.003e+00   5.230e+00 ...,   3.160e-03   6.571e-03\n",
      "    3.457e-15]]\n"
     ]
    }
   ],
   "source": [
    "#In case that correlations exist, we can use PCA to handle them.\n",
    "# Feature Extraction with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# feature extraction\n",
    "pca = PCA(n_components=700)\n",
    "finalX = pca.fit_transform(rescaledX)\n",
    "print finalX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "#keeping a test sample to use in our predictions.\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(finalX, Y, test_size=0.20, random_state=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Algorithm Selection\n",
    "Select a set of algorithms to apply, select evaluation metrics, and evaluate/compare algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Evaluation metric:accuracy\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "\n",
    "# Create a list, with one item per algorithm. Each item has a name, and a classifier object.\n",
    "models = []\n",
    "models.append(('LR',  LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('kNN', KNeighborsClassifier()))\n",
    "models.append(('DT',  DecisionTreeClassifier()))\n",
    "models.append(('NB',  GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%03s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std()))\n",
    "    print type(cv_results)\n",
    "\n",
    "plt.boxplot(results)\n",
    "plt.xticks(list(range(1,len(names)+1)), names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Training\n",
    "Apply ensembles and improve performance by hyperparameter optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 0.69725171234332872, 'coef0': 0.41102910240594281, 'tol': 0.5262622111585703, 'shrinking': True, 'gamma': 0.70043142820997084}\n",
      "0.822\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "raise\n"
     ]
    }
   ],
   "source": [
    "#tuning hyperParameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Using RandomizedSearch to tube SVN hyoeroaraneter C\n",
    "\n",
    "param_grid = {'C': uniform(),\n",
    "             'kernel':[ \"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "             'gamma':uniform(),\n",
    "             'coef0':uniform(),\n",
    "             'shrinking':[True, False],\n",
    "             'tol':uniform(),\n",
    "             }\n",
    "model = SVC()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, random_state=7)\n",
    "rsearch.fit(X, Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Finalise Model\n",
    "Predictions on validation set, create model from the entire (training) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.79\n",
      "Confusion matrix\n",
      "[[ 7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 10  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 16  0  0  0  2  0  0  0]\n",
      " [ 0  0  2  9  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  9  0  0  0  0  3]\n",
      " [ 1  0  0  0  0  7  0  0  1  0]\n",
      " [ 0  0  1  0  1  2  5  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  5  0  2]\n",
      " [ 0  1  0  0  0  0  1  0  7  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEmCAYAAAD1FIKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0692142d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "model = SVC(kernel='linear', C= 0.69725171234332872,\n",
    "            coef0=0.41102910240594281, tol=0.5262622111585703,\n",
    "            shrinking=True, gamma=0.70043142820997084)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print \"Score: \", model.score(X_test,y_test)\n",
    "\n",
    "#using Scikit-Learn code:http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "   \n",
    "    print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
